model_name_suffix:
  - adam
  - range
  - test
settings:
  is_lr_range_test: True
  training_steps: 1  # should run for 12000 epochs
  optimizer:
    name: Adam
    parameters:
      beta_1: 0.9
      beta_2: 0.999
      epsilon: !!float "1e-8"
      amsgrad: False
      learning_rate:
        name: TriangularCyclicalLearningRate
        parameters:
          initial_learning_rate: !!float "1e-6"
          maximal_learning_rate: !!float "1.0"
          # Recommended step size would be: 2 * steps per epoch = 2 * 480,
          # however, for the LR range test, the step size is set to the
          # maximum number of steps (iterations).
          # Assuming we train for 25 epochs, we then set it to 25 * 480.
          step_size: 12000
          scale_mode: cycle
